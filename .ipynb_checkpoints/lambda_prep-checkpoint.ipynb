{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75e0064-8a6d-416b-a84e-6c7d19fafcb2",
   "metadata": {},
   "source": [
    "## Import Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40aaa6d-845e-4b10-949b-f2d3e665eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji\n",
    "from nltk import wordpunct_tokenize, word_tokenize, sent_tokenize\n",
    "import io\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d79edc-2114-4ee7-a055-c1ad1411fa97",
   "metadata": {},
   "source": [
    "## Pull in pickled models created in previous script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371cc445-1c9d-4a70-ace8-df761afa7119",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"model.pkl\", 'rb'))\n",
    "loaded_cv = pickle.load(open(\"cv.pkl\", 'rb'))\n",
    "my_dict = pickle.load(open(\"bad_words.pkl\", 'rb'))\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843cb92-2031-4d6a-a163-7112197e05af",
   "metadata": {},
   "source": [
    "# Push Model, CV and Bad Word Dictionary to cloud storage (S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e3631-4bb1-4e7c-800d-01f4c6c8f703",
   "metadata": {},
   "source": [
    "# All pickle files are stored in the \"byu-capstone-appropriate-checker\" bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6221e26-ab85-490d-9818-bcac2630d560",
   "metadata": {},
   "source": [
    "### Define bucket name and key, push pickled model to S3 using the 'model' key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e676e42d-3237-4e40-ba36-56f4620ade41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"byu-capstone-appropriate-checker\"\n",
    "key = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460677fa-fd77-4f9d-9ebc-3f102d1a1d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'RG6E5VVDJ5A1ZH8E',\n",
       "  'HostId': 'KXJoQLUSdtVflxLmDnC77MK6ErEUhMFXiiY0FOfqRt3ZY1J1Njn/fWfzXXNePw0IsKk67+4ZMwc=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'KXJoQLUSdtVflxLmDnC77MK6ErEUhMFXiiY0FOfqRt3ZY1J1Njn/fWfzXXNePw0IsKk67+4ZMwc=',\n",
       "   'x-amz-request-id': 'RG6E5VVDJ5A1ZH8E',\n",
       "   'date': 'Thu, 07 Apr 2022 16:00:52 GMT',\n",
       "   'etag': '\"177333cd821482a81c8bc66d82457226\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"177333cd821482a81c8bc66d82457226\"'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_buffer = io.BytesIO()\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "pickle_byte_obj = pickle.dumps(loaded_model) \n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd1bac-c120-4725-bba3-ce464c3e678c",
   "metadata": {},
   "source": [
    "### Define bucket name and key, push pickled count vectorizer to S3 using the 'count_vectorizer' key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc091712-05e1-43cd-bec5-ed8c750fe83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"count_vectorizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166a0d08-9c9a-4f90-b247-ae3d2a2244a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'DWPSTKHXBKPA66DH',\n",
       "  'HostId': 'ASNPAeh756rLuXK1hToKeNwCKjMuiuD7vHAgZaI51XjMZ9C29TdJptvkIp4DPTPePzKnS+fCJOE=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'ASNPAeh756rLuXK1hToKeNwCKjMuiuD7vHAgZaI51XjMZ9C29TdJptvkIp4DPTPePzKnS+fCJOE=',\n",
       "   'x-amz-request-id': 'DWPSTKHXBKPA66DH',\n",
       "   'date': 'Thu, 07 Apr 2022 16:01:14 GMT',\n",
       "   'etag': '\"8dc4293e591793c0de1a445cf31bd076\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"8dc4293e591793c0de1a445cf31bd076\"'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_buffer = io.BytesIO()\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "pickle_byte_obj = pickle.dumps(loaded_cv) \n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeac3f7-ed42-4c85-a94d-43e07940849c",
   "metadata": {},
   "source": [
    "### Define bucket name and key, push pickled blacklist dictionary to S3 using the 'blacklist_dictionary' key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42caf54c-de05-4164-8c24-d0e01b567b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"blacklist_dictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c7c70a-f8ce-4af5-80b4-7b74cea42bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'Q5KR43SRHWB8K2P1',\n",
       "  'HostId': 'JRGAKcNUJsALh6V1YCI7vCT2hCSTd0Bfa8ddfD897mbTwTnncuZDHtqLK4nt+2TEo1TjfqjwTPY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'JRGAKcNUJsALh6V1YCI7vCT2hCSTd0Bfa8ddfD897mbTwTnncuZDHtqLK4nt+2TEo1TjfqjwTPY=',\n",
       "   'x-amz-request-id': 'Q5KR43SRHWB8K2P1',\n",
       "   'date': 'Thu, 07 Apr 2022 16:01:22 GMT',\n",
       "   'etag': '\"5972924d3e4aa204485d1fe1821eb8a9\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"5972924d3e4aa204485d1fe1821eb8a9\"'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_buffer = io.BytesIO()\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "pickle_byte_obj = pickle.dumps(my_dict) \n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c396361-c189-4f19-9916-eba74df1002d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d52d09-5495-41a1-8770-21a4bbafd6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa5fa93f-2ca0-41a0-95a3-d65c0af5bb93",
   "metadata": {},
   "source": [
    "# Retreive all the previously pushed pickle files from S3 to ensure they work correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1013729-9e74-4499-8f32-725cd84a9b0d",
   "metadata": {},
   "source": [
    "## Retreive model from S3 using previously created key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8512b1e-60d9-4a47-83ce-0077961b89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"byu-capstone-appropriate-checker\"\n",
    "key = \"model\"  \n",
    "s3 = boto3.client('s3')\n",
    "response = s3.get_object(Bucket = bucket, Key = key)\n",
    "model = pickle.loads(response['Body'].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164dc50-b514-4cac-8ddd-d34ed997b081",
   "metadata": {},
   "source": [
    "## Retreive CV from S3 using previously created key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd48ec8-8e58-41eb-9f37-4276ae00d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"byu-capstone-appropriate-checker\"\n",
    "key = \"count_vectorizer\" \n",
    "s3 = boto3.client('s3')\n",
    "response = s3.get_object(Bucket = bucket, Key = key)\n",
    "cv = pickle.loads(response['Body'].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97af861-fb1f-4866-83bc-0fb5475cc89f",
   "metadata": {},
   "source": [
    "## Retreive dictionary from S3 using previously created key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2cc9c5b-f88e-42e9-bcf8-cd0d3f0fe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"byu-capstone-appropriate-checker\"\n",
    "key = \"blacklist_dictionary\"\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.get_object(Bucket = bucket, Key = key)\n",
    "my_dict = pickle.loads(response['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c605362-73b4-44f9-801c-5d4bac66d2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7eead-395c-4837-8c78-f12177f72f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6cf6540-875d-40eb-91e1-08b9f8b20b13",
   "metadata": {},
   "source": [
    "# Test pulled files with example prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc0762-b0d7-47f0-9965-fd5944726e2c",
   "metadata": {},
   "source": [
    "## Create function to clean the data for input into the predict function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "196f006c-3a06-40f1-bfbd-09253571a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "wn = WordNetLemmatizer()\n",
    "sw_special = [\"rt\"]\n",
    "\n",
    "def clean_data(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = text.lower() # coerce data to lower case\n",
    "    tokens = wordpunct_tokenize(text) # tokenize individual words\n",
    "    tokens = [tok for tok in tokens if tok.isalnum()] # removing punctuation\n",
    "    tokens = [tok for tok in tokens if tok not in sw] # removing stop words\n",
    "    tokens = [wn.lemmatize(tok) for tok in tokens] # lematizing lyrics - reducing to base words\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da797b7-11a5-4c25-87f3-96e74e6d357a",
   "metadata": {},
   "source": [
    "## Create a function to take input, and predict using the previously instantiated model, vectorizer and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb91609-aa9e-4547-b78c-936b1d67a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(message, model, cv):\n",
    "    # check if any of the words automatically imply inappropriate\n",
    "    for word in message.split():\n",
    "        for char in word:\n",
    "            if char in punc:\n",
    "                word = word.replace(char, \"\")\n",
    "        if word.lower() in my_dict:\n",
    "            return 2\n",
    "    sample_text = clean_data(message)\n",
    "    \n",
    "    sample_text = [sample_text]\n",
    "    sample_cv = cv.transform(sample_text)\n",
    "    \n",
    "    sample_df = pd.DataFrame(sample_cv.toarray(), columns = cv.get_feature_names())\n",
    "    \n",
    "    # predict on sample message\n",
    "    val = model.predict(sample_df)[0]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78d6bc-e705-48bd-a249-97432788ae28",
   "metadata": {},
   "source": [
    "## Test the predict function with user input, created model, and created count vectorizer - 0 indicates appropriate, 1 potentially inappropriate, and 2 blatantly inappropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "940a80e0-13a5-4ce5-ad98-abab723f8143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i hate you\", model, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04439b7c-c6ff-4a85-be91-82a1a68e5d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
