{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize, word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import emoji\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Cleaning Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "def clean_data(text):\n",
    "    text = emoji.demojize(text) # convert the emoji to it's textual meaning \n",
    "    text = text.lower() # coerce data to lower case\n",
    "    tokens = wordpunct_tokenize(text) # tokenize individual words\n",
    "    tokens = [tok for tok in tokens if tok.isalnum()] # removing punctuation\n",
    "    tokens = [tok for tok in tokens if tok not in sw] # removing stop words\n",
    "    tokens = [wn.lemmatize(tok) for tok in tokens] # lematizing lyrics - reducing to base words\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for creating training and testing. Takes as input:\n",
    "    - the path to the file where the csv of data is stored\n",
    "    - the column name for where the messages are stored\n",
    "    - the column name for where the labels are stored\n",
    "    - the path to where the training data should be stored\n",
    "    - the path to where the testing data should be stored\n",
    "# It returns:\n",
    "    - a dataframe with testing data\n",
    "    - a dataframe with training data\n",
    "# It also: \n",
    "    - exports both training and testing data to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_datasets(filepath, message_column_label, label_column_label, training_data_path, testing_data_path):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[message_column_label] =df[message_column_label].astype(str)\n",
    "    df = df.dropna()\n",
    "    df = df[~df[label_column_label].isin(['10', '$0'])]\n",
    "    df[label_column_label] = df[label_column_label].astype(int)\n",
    "    df[message_column_label] = df[message_column_label].apply(lambda x: clean_data(x))\n",
    "    df = df[df[message_column_label] != '']\n",
    "    df = df[df[message_column_label] != '']\n",
    "    \n",
    "    bad_messages = df[df[label_column_label] == 1]\n",
    "    bad_train = bad_messages.head(int(len(bad_messages)*(70/100)))\n",
    "    bad_train = bad_train.reset_index(drop=True)\n",
    "    bad_test = bad_messages.iloc[max(bad_train.index):]\n",
    "\n",
    "    fine_messages = df[df[label_column_label] == 0]\n",
    "    fine_train = fine_messages.head(3578)\n",
    "    fine_train = fine_train.reset_index(drop=True)\n",
    "    fine_messages = fine_messages.iloc[3579:]\n",
    "    fine_messages = fine_messages.sample(frac=1).reset_index(drop=True)\n",
    "    fine_test = fine_messages.head(1535)\n",
    "\n",
    "\n",
    "    train = pd.concat([bad_train, fine_train], axis=0)\n",
    "    test = pd.concat([bad_test, fine_test], axis=0)\n",
    "\n",
    "    train = train.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    train.to_csv(training_data_path)\n",
    "    test.to_csv(testing_data_path)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A scoring function used to test the acccuracy of the two-pronged approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(preds, labels):\n",
    "    total_same = 0\n",
    "    total_pos = 0\n",
    "    total_neg = 0\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    false_positives = 0\n",
    "    for i in range(len(preds)):\n",
    "    #     print(preds[i])\n",
    "    #     print(labels[i])\n",
    "    #     print()\n",
    "        if labels[i] == 1:\n",
    "            total_pos += 1\n",
    "\n",
    "        if labels[i] == 0:\n",
    "            total_neg += 1\n",
    "\n",
    "        if preds[i] == labels[i]:\n",
    "            total_same += 1\n",
    "\n",
    "        if preds[i] == 1 and labels[i] == 1:\n",
    "            true_positives += 1\n",
    "\n",
    "        if preds[i] == 0 and labels[i] == 1:\n",
    "            false_negatives += 1\n",
    "\n",
    "        if preds[i] == 1 and labels[i] == 0:\n",
    "            false_positives += 1\n",
    "\n",
    "    recall =  true_positives / (true_positives + false_negatives)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    return total_same / len(preds), recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicion function used in the real version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(bad_words_filepath, model, cv, messages):\n",
    "    df = pd.read_csv(bad_words_filepath)\n",
    "    df = list(df)\n",
    "\n",
    "    my_dict = {}\n",
    "    for i in range(len(df)):\n",
    "        df[i] = df[i].strip()\n",
    "    for i in df:\n",
    "        my_dict[i] = 1\n",
    "\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    \n",
    "    predictions = []\n",
    "    for message in messages:\n",
    "        checked = False\n",
    "        # check if any of the words automatically imply inappropriate\n",
    "        for word in message.split():\n",
    "            for char in word:\n",
    "                if char in punc:\n",
    "                    word = word.replace(char, \"\")\n",
    "            if word.lower() in my_dict:\n",
    "                predictions.append(1)\n",
    "                checked = True\n",
    "                break\n",
    "        if checked:\n",
    "            continue\n",
    "                \n",
    "        sample_text = clean_data(message)\n",
    "\n",
    "        sample_text = [sample_text]\n",
    "        sample_cv = cv.transform(sample_text)\n",
    "\n",
    "        sample_df = pd.DataFrame(sample_cv.toarray(), columns = cv.get_feature_names())\n",
    "\n",
    "        # predict on sample message\n",
    "        val = model.predict(sample_df)[0]\n",
    "        predictions.append(val)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train a random forest classifier\n",
    "This function will train and test the model until it finds one with an acceptable accuracy. This is necessary because of the random nature of the random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data, testing_data, message_column_label, label_column_label, bad_words_filepath):\n",
    "    best_cv = None\n",
    "    best_classifier = None\n",
    "    best_accuracy = 0\n",
    "    while best_accuracy < 0.82:\n",
    "        cv = CountVectorizer(max_features = 3000)\n",
    "        X = cv.fit_transform(training_data[message_column_label]).toarray()\n",
    "        y = training_data[label_column_label].values\n",
    "\n",
    "        rf = RandomForestClassifier() \n",
    "        rf.fit(X, y)\n",
    "        \n",
    "        test_X = testing_data[message_column_label]\n",
    "        test_y = testing_data[label_column_label].values\n",
    "\n",
    "        y_hat = predict(bad_words_filepath, rf, cv, test_X)\n",
    "        print(len(y_hat))\n",
    "        accuracy, recall, precision, f1 = getScores(y_hat, test_y)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_classifier = rf\n",
    "            best_cv = cv\n",
    "    return best_classifier, best_cv, accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling the model, vectorizer, and dictionary of bad words to be put up on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_model(model_filename, model, cv_filename, cv, dictionary_filename, dictionary):\n",
    "    pickle.dump(model, open(model_filename, 'wb'))\n",
    "    pickle.dump(cv, open(cv_filename, 'wb'))\n",
    "    pickle.dump(dictionary, open(dictionary_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example to get you started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = make_train_test_datasets(\"mutual_messages.csv\", \"Message\", \"Is Inappropriate\", \"training.csv\", \"testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3070\n",
      "3070\n",
      "3070\n"
     ]
    }
   ],
   "source": [
    "classifier, cv, accuracy, recall, precision, f1 = train_model(training, testing, \"Message\", \"Is Inappropriate\", \"dictionary/bad_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495114006514658\n",
      "0.8175895765472313\n",
      "0.8733472512178149\n",
      "0.844549125168237\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dictionary/bad_words.csv\")\n",
    "df = list(df)\n",
    "\n",
    "my_dict = {}\n",
    "for i in range(len(df)):\n",
    "    df[i] = df[i].strip()\n",
    "for i in df:\n",
    "    my_dict[i] = 1\n",
    "    \n",
    "pickle_model(\"model.pkl\", classifier, \"cv.pkl\", cv, \"bad_words\", my_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
